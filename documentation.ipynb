{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.8 64-bit",
   "display_name": "Python 3.7.8 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "e5030792b3492f6b12d94f1f48beca3d8e59ec05fd59d0aaaa48e684281ed297"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Container Pre-marshalling Problem Enviroment\n",
    "En el siguiente documento se documentará cómo es que funciona el CPMP Enviroment\n",
    "\n",
    "## Valores Relevantes\n",
    "\n",
    "state : Es la representación del estado actual, de tipo 'Yard' para permitir realizarle cambios al estado\n",
    "\n",
    "showDebug : Valor booleano que dicta si mostrará información de Debug o no\n",
    "\n",
    "max_step : Pasos máximos, cálculados por una solución greedy. La idea es que la red mejore lo que dicta el greedy en StackedYard.py\n",
    "\n",
    "training :  booleano que dice si está entrenando o no. Más que nada para ver qué conjunto utilizará para trabajar.\n",
    "\n",
    "fileStack :  Los archivos que contienen los estados\n",
    "\n",
    "current_step : Paso actual del estado, la idea es que sea menor a max_step\n",
    "\n",
    "last_reward : la última recompenza obtenida, utilizada para recompenzar la diferencia entre la actual recompenza y la anterior (last_reward)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Acciones\n",
    "La acción que entregará como output va a ser un número de 0 a x, dónde x será la anchura del estado\n",
    "\n",
    "Este valor representa el stack en el cuál se debe realizar la acción. En la actualidad, la red identificará un stack y una función de greedy realizará el cambio en dicho stack seleccionado.\n",
    "\n",
    "```py\n",
    "self.action_space = spaces.Discrete(x) # de 0 a x\n",
    "```\n",
    "\n",
    "## Observaciones\n",
    "La observación será un arreglo que contendrá:\n",
    "\n",
    "1)  El estado actual del patio con los containers, primero los datos rellenados y luego los vacios (0).\n",
    "Los valores equivalentes al container son numeros enteros pertenecientes a `[0,∞)`. \n",
    "La representación dentro de la observación los normalizara en un rango de `[0,1]`, utilizando una normalización min-max, dónde el minimo y el maximo dependera del  problema que se este resolviendo.\n",
    "\n",
    "2) Además de los valores del estado en sí, se cuenta con un valor booleano (0 ó 1) que representará si una columna se encuentra en orden (1) o no (0).\n",
    "\n",
    "3) Como ultimos datos a concatenar en la observación, tenemos dos valores que representarán el paso actual y los pasos máximos. Los pasos máximos dependerán de lo que diga el greedy al iniciar el problema, la representación dentro de la observación será `pasos_actuales/pasos_maximos` para calcular el paso en el que se encuentra y 1 (`pasos_maximos/pasos_maximos`) para calcular el valor máximo.\n",
    "  \n",
    "Así se vería la observación que alimentará a la red.\n",
    "```\n",
    "[[0.6        0.4        0.73333333 0.46666667 0.6        0.4\n",
    "  0.13333333 1.         0.6        0.46666667 0.86666667 0.46666667\n",
    "  0.13333333 0.26666667 0.4        1.         0.2        0.73333333\n",
    "  0.2        0.8        0.53333333 1.         0.66666667 0.66666667\n",
    "  0.         0.         0.         0.         0.         0.\n",
    "  0.         0.         0.         0.         0.         0.\n",
    "  0.         0.         0.         0.         0.         0.\n",
    "  0.         0.         0.         0.         0.         0.\n",
    "  0.         0.         0.         1.         1.         1.\n",
    "  1.         0.         0.         0.         1.         1.\n",
    "  0.         1.        ]]\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Demonstración\n",
    "A continuación se explicarán funciones del ambiente con ejemplos, de modo que se pueda comprender mejor cómo es que opera.\n",
    "\n",
    "Las funciones tendrán los mismos nombres de los métodos encontrados en `containeryard.py` y `yard.py`.\n",
    "\n",
    "### Crear el estado y manipularlo\n",
    "Para crear el estado, se utilizará `yard.py`, debido a que `containeryard.py` implementará dicha representación a un formato de gym para facilitar el uso en redes de aprendizaje por reforzamiento.\n",
    "\n",
    "A continuación un ejemplo de cómo se crea el estado, con un ejemplo encontrado en este mismo directorio, `example_10_5_0_226.bay`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Representación del Patio de Containers (yard.py)\n",
    "Este archivo será la capa que modificará directamente el estado, el ambiente de gym (`containeryard.py`) la utilizará para no trabajarlo directamente.\n",
    "\n",
    "Los métodos que explicaremos son:\n",
    "\n",
    "`isStackEmpty(i)`: Retornará si el stack i (de 0 a n stacks) se encuentra vacío o no (True/False). Este método será utilizado para saber si es posible sacar un container de dicho stack, ya que si se encuentra vacío no se podrá sacar nada.\n",
    "\n",
    "`isStackFull(i)`: Retornará si el stack i (de 0 a n stacks) se encuentra lleno o no (True/False). Este método será utilizado para saber si es posible poner un container en dicho stack, ya que si se encuentra lleno, no se podrá poner nada sobre este.\n",
    "\n",
    "`moveStack(src, dest)`: Este método utilizará los dos anteriores para ver si es posible realizar una acción. En caso de ser posible, realizará dicha acción y cambiará el estado.\n",
    "\n",
    "`getAsObservation()`: Este método devolverá el estado en formato de observación (sin la normalización), es decir, entregará el estado con los containers NO vacíos primero, y luego pondrá los vacíos, por ejemplo quedaría así: `[4, 3, 6, 7, 4, 4, 0, 0, 0, 0, 0 , ....]`\n",
    "\n",
    "`render(self)`: Este método mostrará el estado de una manera \"humanamente-leíble\"\n",
    "\n",
    "`isSorted(i)`: Verá si un stack i está ordenado o no.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rand\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from containeryard.StackedYard import Layout, greedy_solve, read_file, select_destination_stack\n",
    "from Constants import FILE_PATH\n",
    "\n",
    "import gym\n",
    "from gym import error, spaces, utils\n",
    "from gym.utils import seeding\n",
    "\n",
    "#Archivo de Prueba\n",
    "TEST_FILE = r'./example_10_5_0_226.bay'\n",
    "\n",
    "############################################################################################    \n",
    "# From yard.py\n",
    "class Yard():\n",
    "    def __init__(self, file, fromFile = True):\n",
    "        yardInfo = os.path.basename(file.name).split(\"_\")\n",
    "        self.x,self.y = int(yardInfo[1]), int(yardInfo[2])\n",
    "        self.state = np.zeros(shape=(self.x,self.y), dtype=np.int)\n",
    "\n",
    "        #Loads the data from the file.\n",
    "        lines = file.readlines()\n",
    "        for i in range(len(lines)):\n",
    "            pos = 0\n",
    "            #Preparing the line reading.\n",
    "            for num in lines[i].replace(\"\\n\",\"\").split(\" \"):\n",
    "                if num.isdigit():\n",
    "                    self.state[i][pos] = int(num)\n",
    "                    pos = pos + 1\n",
    "\n",
    "        #######END#####################\n",
    "\n",
    "        self.max = np.amax(self.state)\n",
    "        self.min = np.amin(self.state)\n",
    "\n",
    "    def isStackEmpty(self, i):\n",
    "        return self.state[i][0] == 0\n",
    "\n",
    "    def isStackFull(self, i):\n",
    "        return self.state[i][self.y-1] != 0\n",
    "\n",
    "    def moveStack(self, src, dest):\n",
    "        value = 0\n",
    "        \n",
    "        #---> Primero, verificamos que la accion se pueda realizar.\n",
    "        if self.isStackFull(dest) or self.isStackEmpty(src):\n",
    "            return False\n",
    "\n",
    "        #---> Segundo, conseguimos y eliminamos el valor en top.\n",
    "        for pos in range(self.y-1, -1, -1):\n",
    "            if self.state[src][pos] > 0:\n",
    "                value = self.state[src][pos]\n",
    "                self.state[src][pos] = 0\n",
    "                break\n",
    "\n",
    "        #---> Dejamos el valor \n",
    "        for pos in range(self.y):\n",
    "            if self.state[dest][pos] == 0:\n",
    "                self.state[dest][pos] = value\n",
    "                break\n",
    "        return True\n",
    "\n",
    "    def getAsObservation(self):\n",
    "        stateCopy = np.array(self.state, copy=True, dtype=np.float)\n",
    "\n",
    "        return np.concatenate( (stateCopy[np.nonzero(stateCopy)],stateCopy[np.nonzero(stateCopy == 0)]))\n",
    "\n",
    "    def render(self):\n",
    "        rend = np.rot90(self.state, k=1)\n",
    "        print(rend)\n",
    "\n",
    "    def isSorted(self, i):\n",
    "        lastNum = 999999\n",
    "        for num in np.array(self.state[i]):\n",
    "            if num == 0:\n",
    "                break\n",
    "            if num > lastNum:\n",
    "                return False\n",
    "            lastNum = num\n",
    "        return True\n",
    "\n",
    "    def asLayout(self):\n",
    "        layoutState = []\n",
    "        for stack in self.state:\n",
    "            s = stack[np.nonzero(stack)] # Get the non zero values\n",
    "            if s.size <= 0:\n",
    "                s = np.array([0])\n",
    "            layoutState.append(s.tolist())\n",
    "\n",
    "        return layoutState\n",
    "\n",
    "    def isDone(self):\n",
    "        for sort in self.getAllSorts():\n",
    "            if not sort:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def getAllSorts(self):\n",
    "        sorted = np.zeros(self.x, dtype=np.bool)\n",
    "        for i in range(self.x):\n",
    "            sorted[i] = self.isSorted(i)\n",
    "        return sorted\n"
   ]
  },
  {
   "source": [
    "### Ambiente de CPMP (containeryard.py)\n",
    "ContainerYard se utilizará para que la red pueda tomar la observación y realizar acciones en el estado. Más información sobre gym puede ser leída en su página web: https://gym.openai.com/\n",
    "\n",
    "Los métodos que utilizaremos para explicar serán:\n",
    "`reset()`: Reiniciará el problema actual, cargando otro (En el caso de este ejemplo, siempre cargará uno, pero en la realidad cargará el siguiente!!)\n",
    "\n",
    "`step(action)`: Realizará una acción utilizando _take_action(action), después, calculará la recompensa del estado y entregará la observación, recompensa , un booleano definiendo si el estado es terminal y, opcionalmente, información de debug. \n",
    "\n",
    "`_take_action(action)`: Este método realizará la acción en el estado. Primero calculará lo que se demora el greedy en realizar la acción, y lo guardará para calcular la recompensa. Después, utilizará el método de `Yard`, `moveStack` para realizar la acción en el estado.\n",
    "\n",
    "`_next_observation()`: Entregará la observación para la red, descrita anteriormente en el inicio de este archivo\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################    \n",
    "# From containeryard.py\n",
    "class ContainerYard(gym.Env):\n",
    "    metadata = {'render.modes':['human']}\n",
    "\n",
    "    state : Yard\n",
    "    showDebug : bool\n",
    "    max_stel : int\n",
    "    training : bool\n",
    "    fileStack : list\n",
    "    current_step : int\n",
    "    last_reward : int\n",
    "\n",
    "    def __init__(self, showDebug = False, training=False):\n",
    "        super(ContainerYard, self).__init__()\n",
    "\n",
    "        ### START OF CONFIG ###\n",
    "        self.showDebug = showDebug\n",
    "        self.max_step = 10\n",
    "        self.training = training\n",
    "\n",
    "        #---> Creting the stack for files to use..\n",
    "        self.fileStack = []\n",
    "        \n",
    "        ############################\n",
    "        self.current_step = 0\n",
    "        self.last_reward = 0\n",
    "\n",
    "        # Start The Episode\n",
    "        self.reset()\n",
    "\n",
    "        #Action and Observation Space\n",
    "        self.action_space = spaces.Discrete(self.state.x)\n",
    "        self.observation_space = spaces.Box(low=-1, high=255, shape=(self.state.x*self.state.y + self.state.x + 2 ,), dtype=np.float_)\n",
    "\n",
    "    def reset(self):\n",
    "        #################################################################\n",
    "        # ESTE METODO DE RESET SÓLO CARGARÁ EL ARCHIVO DE PRUEBAS\n",
    "        # PERO EL ORIGINAL CARGARÁ TODOS LOS DISPONIBLES, VER containeryard.py\n",
    "        # Esto es SOLO UN EJEMPLO\n",
    "        #################################################################\n",
    "        # Se carga el Yard desde el archivo designado en TEST_FILE\n",
    "        self.state = Yard(open(TEST_FILE))\n",
    "\n",
    "        # Aquí se cargará el mismo estado, pero en un layout de stacks. Esto sólo será utilizado para\n",
    "        # Resolverlo usando greedy, de modo de sacar el máximo de pasos y la recompensa.\n",
    "        self.layout = read_file(TEST_FILE, self.state.y)\n",
    "        self.max_step = greedy_solve(self.layout)\n",
    "        self.greedy_steps = self.max_step\n",
    "\n",
    "        self.current_step = 0\n",
    "\n",
    "        return self._next_observation()\n",
    "\n",
    "    def step(self, action):\n",
    "        #Taking Action!\n",
    "        ret = self._take_action(action)\n",
    "\n",
    "        #New Greedy Value.\n",
    "        self.greedy_steps = greedy_solve(\n",
    "            Layout(self.state.asLayout(), self.state.y)\n",
    "        )\n",
    "\n",
    "        self.current_step += 1\n",
    "\n",
    "\n",
    "        formula_reward = np.exp(-(self.current_step + self.greedy_steps))\n",
    "\n",
    "        reward = formula_reward - self.last_reward\n",
    "\n",
    "        self.last_reward = formula_reward\n",
    "\n",
    "        done = (self.state.isDone() or self.current_step >= self.max_step)\n",
    "\n",
    "        if ret is False:\n",
    "            #Could not make action, so we punish it.\n",
    "            reward = -1\n",
    "\n",
    "        obs = self._next_observation()\n",
    "\n",
    "        return obs, reward, done, _\n",
    "\n",
    "    def _take_action(self, action):\n",
    "\n",
    "        layoutState = self.state.asLayout()\n",
    "        dest = select_destination_stack(\n",
    "            Layout(layoutState, self.state.y), \n",
    "            action\n",
    "        )\n",
    "        return self.state.moveStack(action, dest)\n",
    "\n",
    "    def _next_observation(self):\n",
    "        \n",
    "        #Normalization and Generating the Yard Observation\n",
    "        obs = self.state.getAsObservation()\n",
    "        obsMax = self.state.max\n",
    "        obsMin = self.state.min\n",
    "        for i in range(len(obs)):\n",
    "            obs[i] = (obs[i]-obsMin)/(obsMax-obsMin)\n",
    "\n",
    "        \n",
    "        #Misc Observation\n",
    "        for i in range(self.state.x):\n",
    "            obs = np.insert(obs, obs.size, 1 if self.state.isSorted(i) is True else 0)\n",
    "        \n",
    "        #Normalizated Values\n",
    "        cStep = (self.current_step)/(self.max_step)\n",
    "        mStep = (self.max_step)/(self.max_step)\n",
    "        obs = np.insert(obs, obs.size, [cStep, mStep])\n",
    "        \n",
    "        #self.state.render()\n",
    "        return obs"
   ]
  },
  {
   "source": [
    "### Pruebas\n",
    "Aquí realizaremos pruebas para que se comprenda el funcionamiento.\n",
    "\n",
    "Iniciaremos el estado y probaremos sus funcionamientos básicos.\n",
    "\n",
    "`gym_representation` será nuestro ambiente de gym, primero mostraremos con `.state.render()` cómo es que verá la persona el ambiente y con `._next_observation()` lo que ve la red."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "PARA HUMANOS\n[[ 2  0  0  3  0  0  0  0  0  3]\n [14  0  0  2  0  0  0  0  0 12]\n [ 8  0  0 14  0  0  0  0  0 14]\n [14  0  0  1  5  0  0  0  0  8]\n [ 8  0 13 13 15  0 15  0  0 13]]\n\nPARA REDES\n[0.53333333 0.93333333 0.53333333 0.93333333 0.13333333 0.86666667\n 0.86666667 0.06666667 0.93333333 0.13333333 0.2        1.\n 0.33333333 1.         0.86666667 0.53333333 0.93333333 0.8\n 0.2        0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         1.         1.         0.\n 1.         1.         1.         1.         1.         0.\n 0.         1.        ]\n"
    }
   ],
   "source": [
    "gym_representation = ContainerYard()\n",
    "\n",
    "print('PARA HUMANOS')\n",
    "gym_representation.state.render()\n",
    "\n",
    "print('\\nPARA REDES')\n",
    "print(gym_representation._next_observation())"
   ]
  },
  {
   "source": [
    "Ahora, probaremos un par de funciones.\n",
    "Comenzaremos probando realizar un movimiento sobre la columna numero 3 (Si contamos desde 0, sería la número 2.)\n",
    "\n",
    "El método retornara cuatro valores:\n",
    "La nueva observación, la recompensa, si el estado es terminal y, por último, información adicional opcional."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Información de Retorno:\n(array([0.53333333, 0.93333333, 0.53333333, 0.93333333, 0.13333333,\n       0.86666667, 0.06666667, 0.93333333, 0.13333333, 0.2       ,\n       1.        , 0.33333333, 1.        , 0.86666667, 0.86666667,\n       0.53333333, 0.93333333, 0.8       , 0.2       , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 1.        , 1.        , 0.        , 1.        ,\n       1.        , 1.        , 1.        , 1.        , 0.        ,\n       0.2       , 1.        ]), -1, False, (array([0.53333333, 0.93333333, 0.53333333, 0.93333333, 0.13333333,\n       0.86666667, 0.06666667, 0.93333333, 0.13333333, 0.2       ,\n       1.        , 0.33333333, 1.        , 0.86666667, 0.86666667,\n       0.53333333, 0.93333333, 0.8       , 0.2       , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ,\n       0.        , 1.        , 1.        , 0.        , 1.        ,\n       1.        , 1.        , 1.        , 1.        , 0.        ,\n       0.1       , 1.        ]), 6.14421235332821e-06, False, &#39;&#39;))\n\nRender:\n[[ 2  0  0  3  0  0  0  0  0  3]\n [14  0  0  2  0  0  0  0  0 12]\n [ 8  0  0 14  0  0  0  0  0 14]\n [14  0  0  1  5  0 13  0  0  8]\n [ 8  0  0 13 15  0 15  0  0 13]]\n"
    }
   ],
   "source": [
    "print(\"Información de Retorno:\")\n",
    "print(gym_representation.step(2))\n",
    "\n",
    "print(\"\\nRender:\")\n",
    "gym_representation.state.render()"
   ]
  },
  {
   "source": [
    "A continuación utilizaremos los métodos que se utilizan dentro de todas las funciones:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Stacks Ordenados: \n[False  True  True False  True  True  True  True  True False]\n\nEs Estado Terminal: \nFalse\n\nValor Greedy Estado Actual - Pasos Tomados: \n11 1\n\nEstado Actual:\n[[ 2  0  0  3  0  0  0  0  0  3]\n [14  0  0  2  0  0  0  0  0 12]\n [ 8  0  0 14  0  0  0  0  0 14]\n [14  0  0  1  5  0 13  0  0  8]\n [ 8  0  0 13 15  0 15  0  0 13]]\n"
    }
   ],
   "source": [
    "print(\"Stacks Ordenados: \")\n",
    "print(gym_representation.state.getAllSorts())\n",
    "\n",
    "\n",
    "print(\"\\nEs Estado Terminal: \")\n",
    "print(gym_representation.state.isDone())\n",
    "\n",
    "print(\"\\nValor Greedy Estado Actual - Pasos Tomados: \")\n",
    "print(greedy_solve(Layout(gym_representation.state.asLayout(), gym_representation.state.y)), gym_representation.current_step)\n",
    "\n",
    "print('\\nEstado Actual:')\n",
    "gym_representation.state.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}